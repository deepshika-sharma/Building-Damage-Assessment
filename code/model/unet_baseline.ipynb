{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unet_baseline.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1eF3hEkC-YDlXgPrAsHAOvn01b6vhJSuX","authorship_tag":"ABX9TyPYLlZjg9QQi7d4Ma5igNS3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# import files\n","!cp /content/drive/MyDrive/capstone/src/dataset.py .\n","!cp /content/drive/MyDrive/capstone/src/models.py .\n","!cp /content/drive/MyDrive/capstone/src/utils.py .\n","!cp /content/drive/MyDrive/capstone/src/metrics.py .\n","!cp /content/drive/MyDrive/capstone/src/losses.py ."],"metadata":{"id":"Rr0VPUILun1G","executionInfo":{"status":"ok","timestamp":1652637870984,"user_tz":-720,"elapsed":1549,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from dataset import *\n","from models import Unet_Loc, UNet_Double\n","from utils import AverageMeter\n","from metrics import *\n","from os import path, makedirs, listdir\n","from sklearn.model_selection import train_test_split\n","from losses import *\n","import timeit\n","from torch.backends import cudnn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.optim import lr_scheduler\n","import torch.optim as optim\n","import torch\n","from torch import nn\n","from tqdm import tqdm\n","import gc\n","from PIL import Image, ImageDraw\n","import json\n","from IPython.display import display\n","from shapely import wkt\n","from shapely.geometry.multipolygon import MultiPolygon\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg"],"metadata":{"id":"R9V2KUgKuReP","executionInfo":{"status":"ok","timestamp":1652687430120,"user_tz":-720,"elapsed":376,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["train_dir = '/content/drive/MyDrive/capstone/data/split_data/'"],"metadata":{"id":"mo-4ZTE9yi2w","executionInfo":{"status":"ok","timestamp":1652637876158,"user_tz":-720,"elapsed":5,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["img_list = listdir('/content/drive/MyDrive/capstone/data/split_data/images')"],"metadata":{"id":"64gWitt6mH9T","executionInfo":{"status":"ok","timestamp":1652639033274,"user_tz":-720,"elapsed":507222,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["mask_list = listdir('/content/drive/MyDrive/capstone/data/split_data/masks')"],"metadata":{"id":"RiBXhQyYmLJv","executionInfo":{"status":"ok","timestamp":1652639756002,"user_tz":-720,"elapsed":70306,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["len(mask_list), len(img_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lp8EGnQ4w7I","executionInfo":{"status":"ok","timestamp":1652639760106,"user_tz":-720,"elapsed":514,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}},"outputId":"c29f406e-8845-4570-93ba-ad322723e7fe"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(89568, 89568)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def train_loc_model(model, data_loaders, optimizer, scheduler, seg_loss, num_epochs, weight_dir, snapshot_name, log_dir, best_score=0):\n","    '''\n","    Localization of buildings in the images\n","    '''\n","    writer = SummaryWriter(log_dir + 'localization')\n","    print('Tensorboard is recording into folder: ' + log_dir + 'localization')\n","\n","    torch.cuda.empty_cache()\n","\n","    for epoch in range(num_epochs):\n","        losses = AverageMeter()\n","\n","        dices = AverageMeter()\n","        iterator = data_loaders['train']\n","        iterator = tqdm(iterator)\n","        model.train()\n","        for i, sample in enumerate(iterator):\n","            imgs = sample[\"img\"].cuda(non_blocking=True)\n","            msks = sample[\"msk\"].cuda(non_blocking=True)\n","        \n","            out = model(imgs)\n","\n","            loss = seg_loss(out, msks)\n","\n","            with torch.no_grad():\n","                _probs = torch.sigmoid(out[:, 0, ...])\n","                dice_sc = 1 - dice_round(_probs, msks[:, 0, ...])\n","\n","            losses.update(loss.item(), imgs.size(0))\n","\n","            dices.update(dice_sc, imgs.size(0))\n","\n","            iterator.set_description(\"Epoch {}/{}, lr {:.7f}; Loss {loss.val:.4f} ({loss.avg:.4f}); Dice {dice.val:.4f} ({dice.avg:.4f})\".format(\n","                    epoch, num_epochs, scheduler.get_lr()[-1], loss=losses, dice=dices))\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.999)\n","            optimizer.step()\n","\n","            writer.add_scalar('Train/Loss', losses.avg, epoch)\n","            writer.add_scalar('Train/Dice', dice_sc, epoch)\n","            writer.flush()\n","        \n","        if epoch % 2 == 0:\n","            torch.cuda.empty_cache()\n","\n","            model = model.eval()\n","            dices0 = []\n","\n","            _thr = 0.5\n","            iterator = data_loaders['val']\n","            iterator = tqdm(iterator)\n","            with torch.no_grad():\n","                for i, sample in enumerate(iterator):\n","                    msks = sample[\"msk\"].numpy()\n","                    imgs = sample[\"img\"].cuda(non_blocking=True)\n","            \n","                    out = model(imgs)\n","\n","                    msk_pred = torch.sigmoid(out[:, 0, ...]).cpu().numpy()\n","            \n","                    for j in range(msks.shape[0]):\n","                        dices0.append(dice(msks[j, 0], msk_pred[j] > _thr))\n","\n","            d = np.mean(dices0)\n","\n","            writer.add_scalar('Val/Dice', d, epoch)\n","            writer.flush()\n","\n","            print(\"Val Dice: {}\".format(d))\n","\n","            if d > best_score:\n","                best_score = d\n","                torch.save({\n","                    'epoch': epoch + 1,\n","                    'state_dict': model.state_dict(),\n","                    'best_score': d,\n","                }, path.join(weight_dir, snapshot_name + '_best'))\n","\n","            print(\"score: {}\\tscore_best: {}\".format(d, best_score))\n","\n","        writer.close()\n","            \n","    return best_score"],"metadata":{"id":"l4icX23nwtJ8","executionInfo":{"status":"ok","timestamp":1652639763698,"user_tz":-720,"elapsed":382,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def train_cls_model(model, data_loaders, optimizer, scheduler, seg_loss, ce_loss, num_epochs, weight_dir, snapshot_name, log_dir, best_score=0):\n","    '''\n","    Identifying the level of building damage\n","    '''\n","    torch.cuda.empty_cache()\n","\n","    writer = SummaryWriter(log_dir + 'classification')\n","    print('Tensorboard is recording into folder: ' + log_dir + 'classification')\n","\n","    for epoch in range(num_epochs):\n","        losses = AverageMeter()\n","        dices = AverageMeter()\n","        \n","        iterator = data_loaders['train']\n","        iterator = tqdm(iterator)\n","        model.train()\n","        for i, sample in enumerate(iterator):\n","            imgs = sample[\"img\"].cuda(non_blocking=True)\n","            msks = sample[\"msk\"].cuda(non_blocking=True)\n","            lbl_msk = sample[\"lbl_msk\"].cuda(non_blocking=True)\n","        \n","            out = model(imgs)\n","\n","            loss_loc = seg_loss(out[:, 0, ...], msks[:, 0, ...])\n","            loss1 = seg_loss(out[:, 1, ...], msks[:, 1, ...])\n","            loss2 = seg_loss(out[:, 2, ...], msks[:, 2, ...])\n","            loss3 = seg_loss(out[:, 3, ...], msks[:, 3, ...])\n","            loss4 = seg_loss(out[:, 4, ...], msks[:, 4, ...])\n","\n","            loss5 = ce_loss(out, lbl_msk)\n","\n","            loss = 0.1 * loss_loc + 0.1 * loss1 + 0.3 * loss2 + 0.3 * loss3 + 0.2 * loss4 + loss5 * 11\n","\n","            with torch.no_grad():\n","                _probs = torch.sigmoid(out[:, 0, ...])\n","                dice_sc = 1 - dice_round(_probs, msks[:, 0, ...])\n","\n","            losses.update(loss.item(), imgs.size(0))\n","\n","            dices.update(dice_sc, imgs.size(0))\n","\n","            iterator.set_description(\"Epoch {}/{}, lr {:.7f}; Loss {loss.val:.4f} ({loss.avg:.4f}); Dice {dice.val:.4f} ({dice.avg:.4f})\".format(\n","                    epoch, num_epochs, scheduler.get_lr()[-1], loss=losses, dice=dices))\n","        \n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.999)\n","            optimizer.step()\n","\n","            writer.add_scalar('Train/Loss', losses.avg, epoch)\n","            writer.add_scalar('Train/Dice', dice_sc, epoch)\n","            writer.add_scalar('Train/Loc_loss', loss_loc, epoch)\n","            writer.add_scalar('Train/NoDamage_loss', loss1, epoch)\n","            writer.add_scalar('Train/MinorDamage_loss', loss2, epoch)\n","            writer.add_scalar('Train/MajorDamage_loss', loss3, epoch)\n","            writer.add_scalar('Train/Destroyed_loss', loss4, epoch)\n","            writer.add_scalar('Train/Cls_loss', loss4, epoch)\n","\n","            writer.flush()\n","        \n","        if epoch % 2 == 0:\n","            torch.cuda.empty_cache()\n","\n","            model = model.eval()\n","            dices0 = []\n","\n","            tp = np.zeros((4,))\n","            fp = np.zeros((4,))\n","            fn = np.zeros((4,))\n","\n","            _thr = 0.3\n","            \n","            iterator = data_loaders['val']\n","            iterator = tqdm(iterator)\n","            with torch.no_grad():\n","                for i, sample in enumerate(iterator):\n","                    msks = sample[\"msk\"].numpy()\n","                    lbl_msk = sample[\"lbl_msk\"].numpy()\n","                    imgs = sample[\"img\"].cuda(non_blocking=True)\n","                    out = model(imgs)\n","                    \n","                    msk_pred = torch.sigmoid(out[:, 0, ...]).cpu().numpy()\n","                    msk_damage_pred = torch.sigmoid(out).cpu().numpy()[:, 1:, ...]\n","            \n","                    for j in range(msks.shape[0]):\n","                        dices0.append(dice(msks[j, 0], msk_pred[j] > _thr))\n","\n","                        targ = lbl_msk[j][msks[j, 0] > 0]\n","                        pred = msk_damage_pred[j].argmax(axis=0)\n","                        pred = pred * (msk_pred[j] > _thr)\n","                        pred = pred[msks[j, 0] > 0]\n","                        for c in range(4):\n","                            tp[c] += np.logical_and(pred == c, targ == c).sum()\n","                            fn[c] += np.logical_and(pred != c, targ == c).sum()\n","                            fp[c] += np.logical_and(pred == c, targ != c).sum()\n","\n","            d0 = np.mean(dices0)\n","            f1_sc = np.zeros((4,))\n","            \n","            for c in range(4):\n","                f1_sc[c] = 2 * tp[c] / (2 * tp[c] + fp[c] + fn[c])\n","\n","            f1 = 4 / np.sum(1.0 / (f1_sc + 1e-6))\n","\n","            sc = 0.3 * d0 + 0.7 * f1\n","            print(\"Val Score: {}, Dice: {}, F1: {}, F1_no-damage: {}, F1_minor-damage: {}, F1_major-damage: {}, F1_destroyed: {}\".format(\n","                sc, d0, f1, f1_sc[0], f1_sc[1], f1_sc[2], f1_sc[3]))\n","\n","            writer.add_scalar('Val/Score', sc, epoch)\n","            writer.add_scalar('Val/Dice', d0, epoch)\n","            writer.add_scalar('Val/NoDamage_F1', f1, epoch)\n","            writer.add_scalar('Val/MinorDamage_F1', f1_sc[0], epoch)\n","            writer.add_scalar('Val/MajorDamage_F1', f1_sc[1], epoch)\n","            writer.add_scalar('Val/Destroyed_F1', f1_sc[2], epoch)\n","            writer.add_scalar('Val/Cls_F1', f1_sc[3], epoch)\n","\n","            writer.flush()\n","            \n","            if sc > best_score:\n","                torch.save({\n","                    'epoch': epoch + 1,\n","                    'state_dict': model.state_dict(),\n","                    'best_score': sc,\n","                }, path.join(weight_dir, snapshot_name + '_best'))\n","                best_score = sc\n","\n","            print(\"score: {}\\tscore_best: {}\".format(sc, best_score))\n","        \n","        writer.close()\n","\n","    return best_score"],"metadata":{"id":"Fq8x0nM8xSGs","executionInfo":{"status":"ok","timestamp":1652639766349,"user_tz":-720,"elapsed":703,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def main_loc(train_dir, img_list):\n","    # train_dirs = ['/content/drive/MyDrive/capstone/data/split_data']\n","    weight_dir = 'weights'\n","    makedirs(weight_dir, exist_ok=True)\n","    snapshot_name = '_unet_loc'\n","\n","    log_dir = 'logs/unet_base/'\n","    makedirs(log_dir, exist_ok=True)\n","\n","    all_files = []\n"," \n","    for f in img_list:\n","        if '_pre_disaster' in f:\n","            all_files.append(path.join(train_dir, 'images', f))\n","\n","    # print(len(all_files))\n","    # all_files = all_files[:200]\n","    \n","    cudnn.benchmark = True\n","\n","    batch_size = 16\n","    val_batch_size = 8\n","\n","    train_idxs, val_idxs = train_test_split(np.arange(len(all_files)), test_size=0.2, random_state=42)\n","    print('train: ', len(train_idxs), ' validation: ', len(val_idxs))\n","\n","    steps_per_epoch = len(train_idxs) // batch_size\n","    validation_steps = len(val_idxs) // val_batch_size\n","\n","    print('steps_per_epoch', steps_per_epoch, 'validation_steps', validation_steps)\n","\n","    data_train = TrainDataLoc(train_idxs, all_files=all_files)\n","    val_train = ValDataLoc(val_idxs, all_files=all_files)\n","\n","    train_data_loader = DataLoader(data_train, batch_size=batch_size, num_workers=4, shuffle=True, pin_memory=False, drop_last=True)\n","    val_data_loader = DataLoader(val_train, batch_size=val_batch_size, num_workers=4, shuffle=False, pin_memory=False)\n","\n","    data_loaders = {\n","        'train': train_data_loader,\n","        'val': val_data_loader\n","    }\n","\n","    num_epochs = 5\n","\n","    model = Unet_Loc(bilinear=False).cuda()\n","    \n","    model = nn.DataParallel(model).cuda()\n","\n","    seg_loss = ComboLoss({'dice': 1.0, 'focal': 10.0}, per_image=False).cuda()\n","\n","    optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n","\n","    scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n","    \n","    try:\n","        snap_to_load = '_unet_loc_best'\n","        print(\"=> loading checkpoint '{}'\".format(snap_to_load))\n","        checkpoint = torch.load(path.join(weight_dir, snap_to_load), map_location='cpu')\n","        loaded_dict = checkpoint['state_dict']\n","        state_dict = model.state_dict()\n","        for k in state_dict:\n","            if k in loaded_dict and state_dict[k].size() == loaded_dict[k].size():\n","                state_dict[k] = loaded_dict[k]\n","        # loaded_dict = sd\n","        model.load_state_dict(state_dict)\n","        print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","                .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","        best_score = checkpoint['best_score']\n","        del loaded_dict\n","        del state_dict\n","        del checkpoint\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    except:\n","        best_score = 0\n","\n","    history = train_loc_model(model=model, data_loaders=data_loaders, optimizer=optimizer_ft, scheduler=scheduler, seg_loss=seg_loss, num_epochs=num_epochs, weight_dir=weight_dir, snapshot_name=snapshot_name, log_dir=log_dir, best_score=best_score)\n","\n","    return history"],"metadata":{"id":"mObITY5oxwe5","executionInfo":{"status":"ok","timestamp":1652639770958,"user_tz":-720,"elapsed":504,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def main_cls(train_dir, img_list, mask_list):\n","    # train_dirs = ['/content/drive/MyDrive/capstone/data/split_data']\n","    weight_dir = 'weights'\n","    makedirs(weight_dir, exist_ok=True)\n","    snapshot_name = '_unet_cls'\n","    \n","    log_dir = 'logs/unet_base/'\n","    makedirs(log_dir, exist_ok=True)\n","\n","    all_files = []\n","    for f in img_list:\n","        if '_pre_disaster' in f:\n","            all_files.append(path.join(train_dir, 'images', f))\n","\n","    # print(len(all_files))\n","\n","    file_classes = []\n","    for fn in all_files:\n","        fl = np.zeros((4,), dtype=bool)\n","        msk1 = cv2.imread(fn.replace('/images/', '/masks/').replace('_pre_disaster', '_post_disaster'), cv2.IMREAD_UNCHANGED)\n","        for c in range(1, 5):\n","            fl[c-1] = c in msk1\n","        file_classes.append(fl)\n","    file_classes = np.asarray(file_classes)\n","\n","    cudnn.benchmark = True\n","\n","    batch_size = 8\n","    val_batch_size = 4\n","\n","    train_idxs0, val_idxs = train_test_split(np.arange(len(all_files)), test_size=0.2, random_state=42)\n","    print('train: ', len(train_idxs0), ' validation: ', len(val_idxs))\n","\n","    train_idxs = []\n","    for i in train_idxs0:\n","        train_idxs.append(i)\n","        if file_classes[i, 1:].max():\n","            train_idxs.append(i)\n","        if file_classes[i, 1:3].max():\n","                train_idxs.append(i)\n","    train_idxs = np.asarray(train_idxs)\n","\n","    steps_per_epoch = len(train_idxs) // batch_size\n","    validation_steps = len(val_idxs) // val_batch_size\n","\n","    print('steps_per_epoch', steps_per_epoch, 'validation_steps', validation_steps)\n","\n","    data_train = TrainDataCls(train_idxs, all_files)\n","    val_train = ValDataCls(val_idxs, all_files)\n","\n","    train_data_loader = DataLoader(data_train, batch_size=batch_size, num_workers=6, shuffle=True, pin_memory=False, drop_last=True)\n","    val_data_loader = DataLoader(val_train, batch_size=val_batch_size, num_workers=6, shuffle=False, pin_memory=False)\n","\n","    data_loaders = {\n","        'train': train_data_loader,\n","        'val': val_data_loader\n","    }\n","\n","    num_epochs = 5\n","\n","    model = UNet_Double(bilinear=False).cuda()\n","    \n","    model = nn.DataParallel(model).cuda()\n","\n","    seg_loss = ComboLoss({'dice': 1.0, 'focal': 12.0}, per_image=False).cuda()\n","    ce_loss = nn.CrossEntropyLoss().cuda()\n","\n","    optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n","\n","    scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n","    \n","    try:\n","        snap_to_load = '_unet_cls_best'\n","        print(\"=> loading checkpoint '{}'\".format(snap_to_load))\n","        checkpoint = torch.load(path.join(weight_dir, snap_to_load), map_location='cpu')\n","        loaded_dict = checkpoint['state_dict']\n","        state_dict = model.state_dict()\n","        for k in state_dict:\n","            if k in loaded_dict and state_dict[k].size() == loaded_dict[k].size():\n","                state_dict[k] = loaded_dict[k]\n","        # loaded_dict = sd\n","        model.load_state_dict(state_dict)\n","        print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","                .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","        best_score = checkpoint['best_score']\n","        del loaded_dict\n","        del state_dict\n","        del checkpoint\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    except:    \n","        # Load pretrained with localization\n","        snap_to_load = '_unet_loc_best'\n","        print(\"=> loading checkpoint '{}'\".format(snap_to_load))\n","        checkpoint = torch.load(path.join(weight_dir, snap_to_load), map_location='cpu')\n","        loaded_dict = checkpoint['state_dict']\n","        state_dict = model.state_dict()\n","        for k in state_dict:\n","            if k in loaded_dict and state_dict[k].size() == loaded_dict[k].size():\n","                state_dict[k] = loaded_dict[k]\n","        # loaded_dict = sd\n","        model.load_state_dict(state_dict)\n","        print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","                .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","        best_score = 0\n","        del loaded_dict\n","        del state_dict\n","        del checkpoint\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","    history = train_cls_model(model=model, data_loaders=data_loaders, optimizer=optimizer_ft, scheduler=scheduler, seg_loss=seg_loss, ce_loss=ce_loss, num_epochs=num_epochs, weight_dir=weight_dir, snapshot_name=snapshot_name, log_dir=log_dir, best_score=best_score)\n","\n","\n"],"metadata":{"id":"iwxm-UJiORf8","executionInfo":{"status":"ok","timestamp":1652639771326,"user_tz":-720,"elapsed":3,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["history = main_loc(train_dir, img_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3EyAiHnAyZUs","executionInfo":{"status":"ok","timestamp":1652650167058,"user_tz":-720,"elapsed":10006470,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}},"outputId":"91c4b21f-ef7b-4840-ba03-ae65be7fd0a5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["train:  35827  validation:  8957\n","steps_per_epoch 2239 validation_steps 1119\n","=> loading checkpoint '_unet_loc_best'\n","Tensorboard is recording into folder: logs/unet_base/localization\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/2239 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:372: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","Epoch 0/5, lr 0.0001000; Loss 0.7776 (0.9866); Dice 0.5554 (0.3660): 100%|██████████| 2239/2239 [1:18:50<00:00,  2.11s/it]\n","100%|██████████| 1120/1120 [15:37<00:00,  1.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Dice: 0.7542961656818253\n","score: 0.7542961656818253\tscore_best: 0.7542961656818253\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5, lr 0.0001000; Loss 0.5927 (0.7462); Dice 0.6727 (0.5629): 100%|██████████| 2239/2239 [17:09<00:00,  2.17it/s]\n","Epoch 2/5, lr 0.0001000; Loss 0.5204 (0.6854); Dice 0.6949 (0.6170): 100%|██████████| 2239/2239 [17:09<00:00,  2.18it/s]\n","100%|██████████| 1120/1120 [01:48<00:00, 10.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Dice: 0.82330286404937\n","score: 0.82330286404937\tscore_best: 0.82330286404937\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5, lr 0.0001000; Loss 0.6080 (0.6367); Dice 0.6767 (0.6430): 100%|██████████| 2239/2239 [17:09<00:00,  2.17it/s]\n","Epoch 4/5, lr 0.0001000; Loss 0.4635 (0.6159); Dice 0.7028 (0.6584): 100%|██████████| 2239/2239 [17:09<00:00,  2.17it/s]\n","100%|██████████| 1120/1120 [01:49<00:00, 10.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Dice: 0.836110556840183\n","score: 0.836110556840183\tscore_best: 0.836110556840183\n"]}]},{"cell_type":"code","source":["def predict_loc():\n","    test_dir = '/content/drive/MyDrive/capstone/data/test/images'\n","    pred_loc_folder = '/content/drive/MyDrive/capstone/data/test/predict/pred-unet_loc'\n","    models_folder = 'weights'\n","\n","    makedirs(pred_loc_folder, exist_ok=True)\n","\n","    snap_to_load = '_unet_loc_best'\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model = Unet_Loc(bilinear=False).to(device)\n","    model = nn.DataParallel(model).to(device)\n","\n","    print(\"=> loading checkpoint '{}'\".format(snap_to_load))\n","    checkpoint = torch.load(path.join(models_folder, snap_to_load), map_location='cpu')\n","    loaded_dict = checkpoint['state_dict']\n","    sd = model.state_dict()\n","    for k in model.state_dict():\n","        if k in loaded_dict and sd[k].size() == loaded_dict[k].size():\n","            sd[k] = loaded_dict[k]\n","    loaded_dict = sd\n","    model.load_state_dict(loaded_dict)\n","    print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","            .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","    model.eval()  \n","\n","    with torch.no_grad():\n","        for f in tqdm(sorted(listdir(test_dir))):\n","            if '_pre_' in f:\n","                fn = path.join(test_dir, f)\n","\n","                image = cv2.imread(fn, cv2.IMREAD_COLOR)\n","                splitted_imgs = split_image(img=image)\n","\n","                splitted_msks = []\n","                for img in splitted_imgs:\n","                    img = preprocess_inputs(img)\n","\n","                    inp = []\n","                    inp.append(img)\n","                    inp.append(img[::-1, ...])\n","                    inp.append(img[:, ::-1, ...])\n","                    inp.append(img[::-1, ::-1, ...])\n","                    inp = np.asarray(inp, dtype='float')\n","                    inp = torch.from_numpy(inp.transpose((0, 3, 1, 2))).float()\n","                    inp = Variable(inp).to(device)\n","\n","                    pred = []             \n","                    msk = model(inp)\n","                    msk = torch.sigmoid(msk)\n","                    msk = msk.cpu().numpy()\n","\n","                    pred.append(msk[0, ...])\n","                    pred.append(msk[1, :, ::-1, :])\n","                    pred.append(msk[2, :, :, ::-1])\n","                    pred.append(msk[3, :, ::-1, ::-1])\n","\n","                    pred_full = np.asarray(pred).mean(axis=0)\n","                    \n","                    msk = pred_full * 255\n","                    msk = msk.astype('uint8').transpose(1, 2, 0)\n","\n","                    splitted_msks.append(msk)\n","\n","                mask = merge_image(splitted_imgs=splitted_msks)\n","                cv2.imwrite(path.join(pred_loc_folder, f.replace('.png', '_part1.png')), mask[..., 0], [cv2.IMWRITE_PNG_COMPRESSION, 9])\n"],"metadata":{"id":"R8CKGtCLnG-P","executionInfo":{"status":"ok","timestamp":1652650253319,"user_tz":-720,"elapsed":365,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["predict_loc()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZoGsw6eocBe","executionInfo":{"status":"ok","timestamp":1652652319407,"user_tz":-720,"elapsed":2047987,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}},"outputId":"90e0dd58-e4d9-40a8-a47b-6761ebdaccdd"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["=> loading checkpoint '_unet_loc_best'\n","loaded checkpoint '_unet_loc_best' (epoch 5, best_score 0.836110556840183)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1886/1886 [34:06<00:00,  1.09s/it]\n"]}]},{"cell_type":"code","source":["history2 = main_cls(train_dir, img_list, mask_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHQC1SThyNvq","outputId":"c100fb6f-9d19-41c1-cde8-01b0f221a583","executionInfo":{"status":"ok","timestamp":1652677700965,"user_tz":-720,"elapsed":25238284,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["train:  35827  validation:  8957\n","steps_per_epoch 6152 validation_steps 2239\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["=> loading checkpoint '_unet_cls_best'\n","=> loading checkpoint '_unet_loc_best'\n","loaded checkpoint '_unet_loc_best' (epoch 5, best_score 0.836110556840183)\n","Tensorboard is recording into folder: logs/unet_base/classification\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/6152 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:372: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","Epoch 0/5, lr 0.0001000; Loss 1.1570 (1.7912); Dice 0.6418 (0.4368): 100%|██████████| 6152/6152 [55:23<00:00,  1.85it/s]\n","100%|██████████| 2240/2240 [07:00<00:00,  5.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: 0.3200909894029174, Dice: 0.6100462640252924, F1: 0.1958244431361853, F1_no-damage: 0.8619923194905049, F1_minor-damage: 0.06433330571959431, F1_major-damage: 0.42541165878535386, F1_destroyed: 0.7289192853744272\n","score: 0.3200909894029174\tscore_best: 0.3200909894029174\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5, lr 0.0001000; Loss 1.0892 (1.1652); Dice 0.5185 (0.6279): 100%|██████████| 6152/6152 [55:25<00:00,  1.85it/s]\n","Epoch 2/5, lr 0.0001000; Loss 0.8520 (1.1098); Dice 0.7468 (0.6689): 100%|██████████| 6152/6152 [55:24<00:00,  1.85it/s]\n","100%|██████████| 2240/2240 [04:12<00:00,  8.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: 0.5510500125068367, Dice: 0.648967448785453, F1: 0.5090853969588582, F1_no-damage: 0.8949309370004604, F1_minor-damage: 0.2719671134734191, F1_major-damage: 0.5807252475911802, F1_destroyed: 0.7457438891273913\n","score: 0.5510500125068367\tscore_best: 0.5510500125068367\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5, lr 0.0001000; Loss 0.8220 (1.0746); Dice 0.6229 (0.6859): 100%|██████████| 6152/6152 [55:25<00:00,  1.85it/s]\n","Epoch 4/5, lr 0.0001000; Loss 1.1586 (1.0480); Dice 0.7629 (0.6994): 100%|██████████| 6152/6152 [55:23<00:00,  1.85it/s]\n","100%|██████████| 2240/2240 [04:10<00:00,  8.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Score: 0.6367771095606061, Dice: 0.7066901913052076, F1: 0.6068143602414912, F1_no-damage: 0.9175321584588102, F1_minor-damage: 0.3779207664764695, F1_major-damage: 0.6628708564941915, F1_destroyed: 0.7422322059861299\n","score: 0.6367771095606061\tscore_best: 0.6367771095606061\n"]}]},{"cell_type":"code","source":["def predict_cls():\n","    test_dir = '/content/drive/MyDrive/capstone/data/test/images'\n","    pred_cls_folder = '/content/drive/MyDrive/capstone/data/test/predict/pred-unet_cls'\n","    models_folder = 'weights'\n","\n","    makedirs(pred_cls_folder, exist_ok=True)\n","\n","    snap_to_load = '_unet_cls_best'\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model = UNet_Double(bilinear=False).to(device)\n","    model = nn.DataParallel(model).to(device)\n","\n","    print(\"=> loading checkpoint '{}'\".format(snap_to_load))\n","    checkpoint = torch.load(path.join(models_folder, snap_to_load), map_location='cpu')\n","    loaded_dict = checkpoint['state_dict']\n","    sd = model.state_dict()\n","    for k in model.state_dict():\n","        if k in loaded_dict and sd[k].size() == loaded_dict[k].size():\n","            sd[k] = loaded_dict[k]\n","    loaded_dict = sd\n","    model.load_state_dict(loaded_dict)\n","    print(\"loaded checkpoint '{}' (epoch {}, best_score {})\"\n","            .format(snap_to_load, checkpoint['epoch'], checkpoint['best_score']))\n","    model.eval()   \n","\n","    with torch.no_grad():\n","        for f in tqdm(sorted(listdir(test_dir))):\n","          try:\n","              if '_pre_' in f:\n","                  fn = path.join(test_dir, f)\n","\n","                  img = cv2.imread(fn, cv2.IMREAD_COLOR)\n","                  img2 = cv2.imread(fn.replace('_pre_', '_post_'), cv2.IMREAD_COLOR)\n","\n","                  image = np.concatenate([img, img2], axis=2)\n","\n","                  splitted_imgs = split_image(img=image)\n","\n","                  splitted_msks = []\n","\n","\n","                  for img in splitted_imgs:\n","\n","                      img = preprocess_inputs(img)\n","\n","                      inp = []\n","                      inp.append(img)\n","                      inp.append(img[::-1, ...])\n","                      inp.append(img[:, ::-1, ...])\n","                      inp.append(img[::-1, ::-1, ...])\n","                      inp = np.asarray(inp, dtype='float')\n","                      inp = torch.from_numpy(inp.transpose((0, 3, 1, 2))).float()\n","                      inp = Variable(inp).to(device)\n","\n","                      pred = []\n","                      \n","                      msk = model(inp)\n","                      msk = torch.sigmoid(msk)\n","                      msk = msk.cpu().numpy()\n","\n","                      pred.append(msk[0, ...])\n","                      pred.append(msk[1, :, ::-1, :])\n","                      pred.append(msk[2, :, :, ::-1])\n","                      pred.append(msk[3, :, ::-1, ::-1])\n","\n","                      pred_full = np.asarray(pred).mean(axis=0)\n","                      \n","                      msk = pred_full * 255\n","                      msk = msk.astype('uint8').transpose(1, 2, 0)\n","\n","                      splitted_msks.append(msk)\n","\n","                  mask = merge_image(splitted_msks)\n","\n","                  cv2.imwrite(path.join(pred_cls_folder, f.replace('.png', '_part1.png')), mask[..., :3], [cv2.IMWRITE_PNG_COMPRESSION, 9])\n","                  cv2.imwrite(path.join(pred_cls_folder, f.replace('.png', '_part2.png')), mask[..., 2:], [cv2.IMWRITE_PNG_COMPRESSION, 9])\n","          except:\n","            pass\n"],"metadata":{"id":"dZ6b_LHpfuhs","executionInfo":{"status":"ok","timestamp":1652682071585,"user_tz":-720,"elapsed":789,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["predict_cls()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fuG8VP4IArw-","executionInfo":{"status":"ok","timestamp":1652686618878,"user_tz":-720,"elapsed":4544826,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}},"outputId":"591ace78-81c8-4392-806d-4e0d293150a8"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["=> loading checkpoint '_unet_cls_best'\n","loaded checkpoint '_unet_cls_best' (epoch 5, best_score 0.6367771095606061)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1880/1880 [1:15:44<00:00,  2.42s/it]\n"]}]},{"cell_type":"code","source":["# checking the images, true vs predicted\n","true_img = listdir('/content/drive/MyDrive/capstone/data/test/labels')\n","pred_img = listdir('/content/drive/MyDrive/capstone/data/test/predict/pred-unet_cls')"],"metadata":{"id":"W97T9UFQOduB","executionInfo":{"status":"ok","timestamp":1652686733075,"user_tz":-720,"elapsed":535,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["def read_label(label_path):\n","    with open(label_path) as json_file:\n","        image_json = json.load(json_file)\n","        return image_json\n","\n","# Color codes for polygons of different damage levels\n","# rgba\n","damage_dict = {\n","    \"no-damage\": (0, 255, 0, 50),  # green\n","    \"minor-damage\": (0, 0, 255, 50),  # blue\n","    \"major-damage\": (255, 69, 0, 50),  # brownish\n","    \"destroyed\": (255, 0, 0, 50),  # red\n","    \"un-classified\": (255, 255, 255, 50)\n","}\n","\n","def get_damage_type(properties):\n","    if 'subtype' in properties:\n","        return properties['subtype']\n","    else:\n","        return 'no-damage'\n","\n","# drawing polygons given coordinates in json\n","def annotate_img(draw, coords):\n","        wkt_polygons = []\n","\n","        for coord in coords:\n","            damage = get_damage_type(coord['properties'])\n","            wkt_polygons.append((damage, coord['wkt']))\n","\n","        polygons = []\n","\n","        for damage, swkt in wkt_polygons:\n","            polygons.append((damage, wkt.loads(swkt)))\n","\n","        for damage, polygon in polygons:\n","            x,y = polygon.exterior.coords.xy\n","            coords = list(zip(x,y))\n","            draw.polygon(coords, damage_dict[damage])\n","\n","        del draw"],"metadata":{"id":"e7ISL23vlBit","executionInfo":{"status":"ok","timestamp":1652686771761,"user_tz":-720,"elapsed":4,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["def display_img(json_path, annotated=True):\n","        \n","    img_path = json_path.replace('labels', 'images').replace('json','png')\n","        \n","    image_json = read_label(json_path)\n","    img_name = image_json['metadata']['img_name']\n","        \n","    print(img_name)\n","    \n","    img = Image.open(img_path)\n","    draw = ImageDraw.Draw(img, 'RGBA')\n","    \n","    if annotated:\n","        annotate_img(draw, image_json['features']['xy'])\n","\n","    return img"],"metadata":{"id":"Eb_noQN5itgh","executionInfo":{"status":"ok","timestamp":1652686772104,"user_tz":-720,"elapsed":2,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["\n","display_img('/content/drive/MyDrive/capstone/data/test/labels/hurricane-florence_00000113_post_disaster.json')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"18YqgK50ls6EDYBoRmcIaC_cxtcKaRVKf"},"id":"1wzYww7JjjSJ","executionInfo":{"status":"ok","timestamp":1652687520641,"user_tz":-720,"elapsed":15616,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}},"outputId":"6de40bca-1069-4064-8442-ae7813872859"},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["img = mpimg.imread('/content/drive/MyDrive/capstone/data/test/predict/pred-unet_cls/hurricane-florence_00000113_pre_disaster_part2.png')\n","plt.imshow(img);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"PQ0lsELYyYK0","executionInfo":{"status":"ok","timestamp":1652687450230,"user_tz":-720,"elapsed":1459,"user":{"displayName":"Deepshika","userId":"10003632373202887278"}},"outputId":"f6a3c00c-b9b2-4725-f717-86641a5af9af"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9db9f063d0>"]},"metadata":{},"execution_count":71},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[""],"metadata":{"id":"-smIcHv217mx"},"execution_count":null,"outputs":[]}]}